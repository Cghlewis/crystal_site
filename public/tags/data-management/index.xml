<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>data management on Crystal Lewis</title>
    <link>https://cghlewis.com/tags/data-management/</link>
    <description>Recent content in data management on Crystal Lewis</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Thu, 16 Feb 2023 00:00:00 +0000</lastBuildDate><atom:link href="https://cghlewis.com/tags/data-management/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Cleaning sample data in standardized way</title>
      <link>https://cghlewis.com/blog/data_clean_03/</link>
      <pubDate>Thu, 16 Feb 2023 00:00:00 +0000</pubDate>
      
      <guid>https://cghlewis.com/blog/data_clean_03/</guid>
      <description>In the previous two posts of this series we reviewed how to standardize the steps in our data cleaning process, as well as practices we can implement to make our workflow more reproducible and reliable. In this final post of the series, I attempt to answer the question, &amp;ldquo;What does this data standardized workflow look like when implemented in the real world?&amp;rdquo;. To tackle this question I created a very simple sample dataset based on the following fictional scenario:</description>
    </item>
    
    <item>
      <title>Creating a data cleaning workflow</title>
      <link>https://cghlewis.com/blog/data_clean_02/</link>
      <pubDate>Wed, 15 Feb 2023 00:00:00 +0000</pubDate>
      
      <guid>https://cghlewis.com/blog/data_clean_02/</guid>
      <description>Data cleaning workflow Data cleaning is the process of organizing and transforming raw data into a format that can be easily interpreted and analyzed. In education research, we are often cleaning data collected in the field from methods such as surveys, assessments, tests, or forms.
Even if we collect data with the most well-designed collection tools, there is most likely at least some cleaning that is needed before you have a dataset that is ready to be shared within or outside of your team.</description>
    </item>
    
    <item>
      <title>Data cleaning for data sharing</title>
      <link>https://cghlewis.com/blog/data_clean_01/</link>
      <pubDate>Tue, 14 Feb 2023 00:00:00 +0000</pubDate>
      
      <guid>https://cghlewis.com/blog/data_clean_01/</guid>
      <description>Through various conversations over the last several months, a recurring question I keep hearing is, what makes a clean dataset? What steps do we expect someone to take before handing off a dataset that is considered &amp;ldquo;clean&amp;rdquo;? And I will tell you right now, there is no standard answer for this question. Even within fields, within projects, or within teams, you will get different answers depending on who you talk to, their role in the research cycle, and their past experiences and/or training with data.</description>
    </item>
    
    <item>
      <title>How to export analysis-ready survey data</title>
      <link>https://cghlewis.com/blog/survey_data/</link>
      <pubDate>Mon, 31 Oct 2022 00:00:00 +0000</pubDate>
      
      <guid>https://cghlewis.com/blog/survey_data/</guid>
      <description>Have you ever downloaded your data from a survey platform and expected it to look like this? ðŸ˜»
But instead you export data that looks like this? ðŸ™€
There are many issues with this data, ranging from unclear and inconsistent value entries, to vague variable names, to conflicting variable types, to multiple things being measured in one variable. While this data can still hopefully be salvaged, the time consuming, decision-heavy process that will go along with cleaning this data is an avoidable step in our data management process.</description>
    </item>
    
    <item>
      <title>Using a data dictionary as your roadmap to quality data</title>
      <link>https://cghlewis.com/blog/data_dictionary/</link>
      <pubDate>Wed, 26 Oct 2022 00:00:00 +0000</pubDate>
      
      <guid>https://cghlewis.com/blog/data_dictionary/</guid>
      <description>A data dictionary, a rectangular format collection of names, definitions, and attributes about variables in a dataset, is arguably the single most important piece of documentation you will create in your research study. While a data dictionary, sometimes also called a codebook or variable information log, is often used as a tool to help you and others interpret your data at the end of your project, it is actually even more powerful if created before you ever collect a single piece of data, serving as a roadmap as you design your data collection tools and clean your data, in order to ultimately get to where you want to go.</description>
    </item>
    
    <item>
      <title>A Curated Collection of Data Management Resources</title>
      <link>https://cghlewis.com/blog/data_mgmt_resources/</link>
      <pubDate>Wed, 14 Sep 2022 00:00:00 +0000</pubDate>
      
      <guid>https://cghlewis.com/blog/data_mgmt_resources/</guid>
      <description>Below are resources for those wanting to learn more about research data management. I have organized resources by type (papers, guides, slides, etc). There are MANY more resources than the ones listed below, but I have narrowed them down to those that I have found most helpful in understanding general best practices in data management and how to implement them into a research workflow.
Resources were last updated on 2023/02/10</description>
    </item>
    
    <item>
      <title>A Synthesis of Data Management Issues</title>
      <link>https://cghlewis.com/blog/synthesis_data_mgmt/</link>
      <pubDate>Wed, 23 Feb 2022 00:00:00 +0000</pubDate>
      
      <guid>https://cghlewis.com/blog/synthesis_data_mgmt/</guid>
      <description>Everyone who works with data has experienced data management difficulties. While it is a pain in the moment to work through those issues, it is refreshing to know that you are never alone. This is evident from the several meetups that have even been started just to commiserate around shared data mishap experiences. Take for instance the Second Annual Data Mishaps Night occurring next Thursday February 24th, or the Be Afraid, Be Very Afraid: Data Management Horror Stories and Lessons Learned sharing session occurring at the COS: Unconference next Friday, February 25th.</description>
    </item>
    
  </channel>
</rss>
