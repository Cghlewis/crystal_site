<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>data cleaning on Crystal Lewis</title>
    <link>https://cghlewis.com/tags/data-cleaning/</link>
    <description>Recent content in data cleaning on Crystal Lewis</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Wed, 10 Jan 2024 00:00:00 +0000</lastBuildDate><atom:link href="https://cghlewis.com/tags/data-cleaning/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Let&#39;s talk about joins</title>
      <link>https://cghlewis.com/blog/joins/</link>
      <pubDate>Wed, 10 Jan 2024 00:00:00 +0000</pubDate>
      
      <guid>https://cghlewis.com/blog/joins/</guid>
      <description>Working with data would be so much simpler if we always only had one dataset to work with. However, in the world of research, we often have multiple datasets, collected from different instruments, participants, or time periods, and our research questions typically require these data to be linked in some way. Yet, before combining data, it&amp;rsquo;s important to consider what type of join makes the most sense for our specific purposes, as well as how to correctly perform those joins.</description>
    </item>
    
    <item>
      <title>Cleaning sample data in standardized way</title>
      <link>https://cghlewis.com/blog/data_clean_03/</link>
      <pubDate>Thu, 16 Feb 2023 00:00:00 +0000</pubDate>
      
      <guid>https://cghlewis.com/blog/data_clean_03/</guid>
      <description>In the previous two posts of this series we reviewed how to standardize the steps in our data cleaning process to produce consistent datasets across the field of education research, as well as practices we can implement to make our data cleaning workflow more reproducible and reliable. In this final post of the series, I attempt to answer the question, &amp;ldquo;What does this process look like when implemented in the real world?</description>
    </item>
    
    <item>
      <title>Creating a data cleaning workflow</title>
      <link>https://cghlewis.com/blog/data_clean_02/</link>
      <pubDate>Wed, 15 Feb 2023 00:00:00 +0000</pubDate>
      
      <guid>https://cghlewis.com/blog/data_clean_02/</guid>
      <description>Data cleaning workflow Data cleaning is the process of organizing and transforming raw data into a format that can be easily interpreted and analyzed. In education research, we are often cleaning data collected in the field from methods such as surveys, assessments, tests, or forms.
Even if we collect data with the most well-designed collection tools, there is most likely at least some cleaning that is needed before you have a dataset that is ready to be shared within or outside of your team.</description>
    </item>
    
    <item>
      <title>Data cleaning for data sharing</title>
      <link>https://cghlewis.com/blog/data_clean_01/</link>
      <pubDate>Tue, 14 Feb 2023 00:00:00 +0000</pubDate>
      
      <guid>https://cghlewis.com/blog/data_clean_01/</guid>
      <description>Through various conversations over the last several months, a recurring question I keep hearing is, what makes a clean dataset? What steps do we expect someone to take before handing off a dataset that is considered &amp;ldquo;clean&amp;rdquo;? And I will tell you right now, there is no standard answer for this question. Even within fields, within projects, or within teams, you will get different answers depending on who you talk to, their role in the research cycle, and their past experiences and/or training with data.</description>
    </item>
    
    <item>
      <title>Four simple ways to integrate your data dictionary into your data cleaning process</title>
      <link>https://cghlewis.com/blog/dict_clean/</link>
      <pubDate>Sun, 27 Nov 2022 00:00:00 +0000</pubDate>
      
      <guid>https://cghlewis.com/blog/dict_clean/</guid>
      <description>In an earlier blog post I argued that data dictionaries are one of the most important pieces of documentation you can keep for a project and I spoke about the four purposes of a data dictionary. One of those purposes being that they can be integrated in your data cleaning process. And when I say &amp;ldquo;integrated&amp;rdquo;, I mean that in both a non-literal sense (for example I can refer to my data dictionary for guidance as to what transformations my data might need), but I also mean it in a very literal sense.</description>
    </item>
    
    <item>
      <title>A Curated Collection of Data Management Resources</title>
      <link>https://cghlewis.com/blog/data_mgmt_resources/</link>
      <pubDate>Wed, 14 Sep 2022 00:00:00 +0000</pubDate>
      
      <guid>https://cghlewis.com/blog/data_mgmt_resources/</guid>
      <description>Below are resources for those wanting to learn more about research data management. I have organized resources by type (papers, guides, slides, etc). There are MANY more resources than the ones listed below, but I have narrowed them down to those that I have found most helpful in understanding general best practices in data management and how to implement them into a research workflow.
Resources were last updated on 2024/05/14</description>
    </item>
    
  </channel>
</rss>
